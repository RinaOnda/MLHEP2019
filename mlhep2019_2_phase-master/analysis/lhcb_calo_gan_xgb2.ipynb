{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "lhcb_calo_gan_xgb2.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [
        "4AVY2qIEVRyy",
        "W_lXgkCoVRy3",
        "vfXLgAbJVRy4",
        "133F5u3xVRzE",
        "Q5xv3LSQVRzH",
        "iIRRXvXRVRzI",
        "GRS1RhPNVRzJ",
        "1rpYu1blVRzK",
        "qF2_ZY_5VRzL"
      ]
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "xYKzGjYgVRwo",
        "colab_type": "code",
        "outputId": "64b1d985-be74-4307-dad6-d76abc7ff899",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 709
        }
      },
      "source": [
        "! wget https://raw.githubusercontent.com/SchattenGenie/mlhep2019_2_phase/master/analysis/calogan_metrics.py\n",
        "! wget https://raw.githubusercontent.com/SchattenGenie/mlhep2019_2_phase/master/analysis/prd_score.py\n",
        "! whet https://raw.githubusercontent.com/SchattenGenie/mlhep2019_2_phase/master/analysis/score.py\n",
        "! wget https://github.com/SchattenGenie/mlhep2019_2_phase/raw/master/analysis/embedder.tp"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-07-07 16:13:06--  https://raw.githubusercontent.com/SchattenGenie/mlhep2019_2_phase/master/analysis/calogan_metrics.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 4115 (4.0K) [text/plain]\n",
            "Saving to: ‘calogan_metrics.py’\n",
            "\n",
            "\rcalogan_metrics.py    0%[                    ]       0  --.-KB/s               \rcalogan_metrics.py  100%[===================>]   4.02K  --.-KB/s    in 0s      \n",
            "\n",
            "2019-07-07 16:13:07 (109 MB/s) - ‘calogan_metrics.py’ saved [4115/4115]\n",
            "\n",
            "--2019-07-07 16:13:08--  https://raw.githubusercontent.com/SchattenGenie/mlhep2019_2_phase/master/analysis/prd_score.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 12426 (12K) [text/plain]\n",
            "Saving to: ‘prd_score.py’\n",
            "\n",
            "prd_score.py        100%[===================>]  12.13K  --.-KB/s    in 0s      \n",
            "\n",
            "2019-07-07 16:13:08 (160 MB/s) - ‘prd_score.py’ saved [12426/12426]\n",
            "\n",
            "/bin/bash: whet: command not found\n",
            "--2019-07-07 16:13:10--  https://github.com/SchattenGenie/mlhep2019_2_phase/raw/master/analysis/embedder.tp\n",
            "Resolving github.com (github.com)... 192.30.253.113\n",
            "Connecting to github.com (github.com)|192.30.253.113|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/SchattenGenie/mlhep2019_2_phase/master/analysis/embedder.tp [following]\n",
            "--2019-07-07 16:13:10--  https://raw.githubusercontent.com/SchattenGenie/mlhep2019_2_phase/master/analysis/embedder.tp\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 569697 (556K) [application/octet-stream]\n",
            "Saving to: ‘embedder.tp’\n",
            "\n",
            "embedder.tp         100%[===================>] 556.34K  --.-KB/s    in 0.05s   \n",
            "\n",
            "2019-07-07 16:13:10 (10.7 MB/s) - ‘embedder.tp’ saved [569697/569697]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AN_OQnIaoQ1y",
        "colab_type": "code",
        "outputId": "3e5a3c9f-ea02-44a3-e74f-71a411862f26",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "!pip install optuna\n",
        "!pip install xgbfir"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting optuna\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/75/ae/925dc830b3c529d0e095fcd5a4e33adfc51d881e60c61857e6158a96d366/optuna-0.13.0.tar.gz (85kB)\n",
            "\u001b[K     |████████████████████████████████| 92kB 4.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: sqlalchemy>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from optuna) (1.3.5)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from optuna) (1.16.4)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from optuna) (1.3.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from optuna) (1.12.0)\n",
            "Collecting cliff (from optuna)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/17/be/3367bc6ec122a2d9c2a6d87ca16fa404c034955a3acc932b52fbd9caf928/cliff-2.15.0-py2.py3-none-any.whl (78kB)\n",
            "\u001b[K     |████████████████████████████████| 81kB 29.0MB/s \n",
            "\u001b[?25hCollecting colorlog (from optuna)\n",
            "  Downloading https://files.pythonhosted.org/packages/68/4d/892728b0c14547224f0ac40884e722a3d00cb54e7a146aea0b3186806c9e/colorlog-4.0.2-py2.py3-none-any.whl\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages (from optuna) (0.24.2)\n",
            "Collecting alembic (from optuna)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7b/8b/0c98c378d93165d9809193f274c3c6e2151120d955b752419c7d43e4d857/alembic-1.0.11.tar.gz (1.0MB)\n",
            "\u001b[K     |████████████████████████████████| 1.0MB 51.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing in /usr/local/lib/python3.6/dist-packages (from optuna) (3.7.4)\n",
            "Collecting pbr!=2.1.0,>=2.0.0 (from cliff->optuna)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f1/f3/9c1fa6496f0adf575441eda21baa6d936395df6c8473c8465d2c525585f6/pbr-5.4.0-py2.py3-none-any.whl (108kB)\n",
            "\u001b[K     |████████████████████████████████| 112kB 53.6MB/s \n",
            "\u001b[?25hCollecting stevedore>=1.20.0 (from cliff->optuna)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/c6/dc/6ee92bccfe3c0448786b30b693e6060d62ec8c4a3ec9a287bac1c1a8d8c9/stevedore-1.30.1-py2.py3-none-any.whl (42kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 27.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: PyYAML>=3.12 in /usr/local/lib/python3.6/dist-packages (from cliff->optuna) (3.13)\n",
            "Collecting cmd2!=0.8.3; python_version >= \"3.0\" (from cliff->optuna)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/39/e7/bd69c2c3e471ae6b408ba7bd1fa5ecfa6bd4884177efea3e7d0d07c8b0b7/cmd2-0.9.14-py3-none-any.whl (98kB)\n",
            "\u001b[K     |████████████████████████████████| 102kB 39.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: PrettyTable<0.8,>=0.7.2 in /usr/local/lib/python3.6/dist-packages (from cliff->optuna) (0.7.2)\n",
            "Requirement already satisfied: pyparsing>=2.1.0 in /usr/local/lib/python3.6/dist-packages (from cliff->optuna) (2.4.0)\n",
            "Requirement already satisfied: python-dateutil>=2.5.0 in /usr/local/lib/python3.6/dist-packages (from pandas->optuna) (2.5.3)\n",
            "Requirement already satisfied: pytz>=2011k in /usr/local/lib/python3.6/dist-packages (from pandas->optuna) (2018.9)\n",
            "Collecting Mako (from alembic->optuna)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/fa/29/8016763284d8fab844224f7cc5675cb4a388ebda0eb5a403260187e48435/Mako-1.0.13.tar.gz (460kB)\n",
            "\u001b[K     |████████████████████████████████| 471kB 60.7MB/s \n",
            "\u001b[?25hCollecting python-editor>=0.3 (from alembic->optuna)\n",
            "  Downloading https://files.pythonhosted.org/packages/c6/d3/201fc3abe391bbae6606e6f1d598c15d367033332bd54352b12f35513717/python_editor-1.0.4-py3-none-any.whl\n",
            "Collecting pyperclip>=1.5.27 (from cmd2!=0.8.3; python_version >= \"3.0\"->cliff->optuna)\n",
            "  Downloading https://files.pythonhosted.org/packages/2d/0f/4eda562dffd085945d57c2d9a5da745cfb5228c02bc90f2c74bbac746243/pyperclip-1.7.0.tar.gz\n",
            "Requirement already satisfied: attrs>=16.3.0 in /usr/local/lib/python3.6/dist-packages (from cmd2!=0.8.3; python_version >= \"3.0\"->cliff->optuna) (19.1.0)\n",
            "Collecting colorama (from cmd2!=0.8.3; python_version >= \"3.0\"->cliff->optuna)\n",
            "  Downloading https://files.pythonhosted.org/packages/4f/a6/728666f39bfff1719fc94c481890b2106837da9318031f71a8424b662e12/colorama-0.4.1-py2.py3-none-any.whl\n",
            "Requirement already satisfied: wcwidth>=0.1.7 in /usr/local/lib/python3.6/dist-packages (from cmd2!=0.8.3; python_version >= \"3.0\"->cliff->optuna) (0.1.7)\n",
            "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.6/dist-packages (from Mako->alembic->optuna) (1.1.1)\n",
            "Building wheels for collected packages: optuna, alembic, Mako, pyperclip\n",
            "  Building wheel for optuna (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Stored in directory: /root/.cache/pip/wheels/79/fa/ab/0bf99de8cffcbce7cd81d8ba83eb22d3a526c3c90b129e3cc1\n",
            "  Building wheel for alembic (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Stored in directory: /root/.cache/pip/wheels/8b/65/b2/9837b4422d13e739c3324c428f1b3aa9e3c3df666bb420e4b3\n",
            "  Building wheel for Mako (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Stored in directory: /root/.cache/pip/wheels/cc/0e/59/0e7f24103d1ebce045037aa17b75548a8387f5e7d2d0011fdc\n",
            "  Building wheel for pyperclip (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Stored in directory: /root/.cache/pip/wheels/92/f0/ac/2ba2972034e98971c3654ece337ac61e546bdeb34ca960dc8c\n",
            "Successfully built optuna alembic Mako pyperclip\n",
            "Installing collected packages: pbr, stevedore, pyperclip, colorama, cmd2, cliff, colorlog, Mako, python-editor, alembic, optuna\n",
            "Successfully installed Mako-1.0.13 alembic-1.0.11 cliff-2.15.0 cmd2-0.9.14 colorama-0.4.1 colorlog-4.0.2 optuna-0.13.0 pbr-5.4.0 pyperclip-1.7.0 python-editor-1.0.4 stevedore-1.30.1\n",
            "Collecting xgbfir\n",
            "  Downloading https://files.pythonhosted.org/packages/72/61/b35d833b93bd8d6ce0418852060504a9e061379fb7e9174b56a16986ca93/xgbfir-0.3.1-py2.py3-none-any.whl\n",
            "Collecting xlsxwriter>=0.9.3 (from xgbfir)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3f/1c/d6d90eb4e94b32b8558296ef197445fb1faca71d747e28ee3ef56f2cfac2/XlsxWriter-1.1.8-py2.py3-none-any.whl (139kB)\n",
            "\u001b[K     |████████████████████████████████| 143kB 5.0MB/s \n",
            "\u001b[?25hInstalling collected packages: xlsxwriter, xgbfir\n",
            "Successfully installed xgbfir-0.3.1 xlsxwriter-1.1.8\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sjyy5wpMVRw4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import torch.utils.data as utils\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm, tqdm_notebook\n",
        "import seaborn as sns\n",
        "from IPython.display import clear_output\n",
        "import xgboost as xgb\n",
        "import xgbfir\n",
        "from hyperopt import fmin, tpe, hp, rand\n",
        "import optuna\n",
        "from sklearn.model_selection import train_test_split\n",
        "sns.set()\n",
        "\n",
        "def one_hot(a, num_classes):\n",
        "    return np.squeeze(np.eye(num_classes)[a.reshape(-1)])\n",
        "\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ekaUZEISVRxE",
        "colab_type": "code",
        "outputId": "7b8f6fe8-c94c-4225-9da1-a1f3efe05b65",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "device"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'cuda'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dGXm-Y21VRxQ",
        "colab_type": "text"
      },
      "source": [
        "## Data pathes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9f8x33gSVRxR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# train_data_path = '/gdrive/My Drive/mlhep2019_gan/data_train.npz'\n",
        "# val_data_path = '/gdrive/My Drive/mlhep2019_gan/data_val.npz'\n",
        "# test_data_path = '/gdrive/My Drive/mlhep2019_gan/data_test.npz'\n",
        "\n",
        "train_data_path = '/gdrive/My Drive/Colab Notebooks/data_train.npz'\n",
        "val_data_path = '/gdrive/My Drive/Colab Notebooks/data_val.npz'\n",
        "test_data_path = '/gdrive/My Drive/Colab Notebooks/data_test.npz'\n",
        "#train_data_path = './data_train.npz'\n",
        "#val_data_path = './data_val.npz'\n",
        "#test_data_path = './data_test.npz'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C9xYt5cj_5j9",
        "colab_type": "code",
        "outputId": "d5ad8581-85fd-480b-baac-b02017fd8ec8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 169
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/gdrive')"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XvVjq3SrVRxV",
        "colab_type": "text"
      },
      "source": [
        "# Loading data\n",
        "\n",
        "Data is stored in `.npz`-format which is a special filetype for persisting multiple NumPy arrays on disk. \n",
        "\n",
        "More info: https://docs.scipy.org/doc/numpy/reference/generated/numpy.lib.format.html#module-numpy.lib.format.\n",
        "\n",
        "File `dat_train.npz` contains four arrays: \n",
        "\n",
        "  * `EnergyDeposit` - images of calorimeters responses\n",
        "  * `ParticleMomentum` - $p_x, p_y, p_z$ of initial partice\n",
        "  * `ParticlePoint` - $x, y$ of initial particle\n",
        "  * `ParticlePDG` - particle type(either $e^-$ or $\\gamma$)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jP9CdpOeVRxW",
        "colab_type": "code",
        "outputId": "4c5332b7-f57d-4145-b130-f931325c75c9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "N = 1000\n",
        "\n",
        "data_train = np.load(train_data_path, allow_pickle=True)\n",
        "print(list(data_train.keys()))\n",
        "\n",
        "# [data_size, 900]\n",
        "EnergyDeposit = data_train['EnergyDeposit'][:N]\n",
        "# reshaping it as [data_size, channels, img_size_x, img_size_y]\n",
        "# channels are needed for pytorch conv2d-layers\n",
        "EnergyDeposit = EnergyDeposit.reshape(-1, 1, 30, 30)\n",
        "\n",
        "# [data_size, 3]\n",
        "ParticleMomentum = data_train['ParticleMomentum'][:N]\n",
        "\n",
        "# [data_size, 2]\n",
        "ParticlePoint = data_train['ParticlePoint'][:, :2][:N]\n",
        "\n",
        "# [data_size, 1]\n",
        "ParticlePDG = data_train['ParticlePDG'][:N]"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['EnergyDeposit', 'ParticlePoint', 'ParticleMomentum', 'ParticlePDG']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1ll4ETT7VRxd",
        "colab_type": "text"
      },
      "source": [
        "## Load it to pytorch `DataLoader`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jknu_w5VVRxe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "EnergyDeposit = torch.tensor(EnergyDeposit).float()\n",
        "ParticleMomentum = torch.tensor(ParticleMomentum).float()\n",
        "ParticlePoint = torch.tensor(ParticlePoint).float()\n",
        "ParticleMomentum_ParticlePoint = torch.cat([ParticleMomentum, ParticlePoint], dim=1)\n",
        "\n",
        "BATCH_SIZE = 128\n",
        "calo_dataset = utils.TensorDataset(EnergyDeposit, ParticleMomentum, ParticlePoint)\n",
        "calo_dataloader = torch.utils.data.DataLoader(calo_dataset, batch_size=BATCH_SIZE, pin_memory=True, shuffle=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3mTvdF_rVRxg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for EnergyDeposit_b, ParticleMomentum_b, ParticlePoint_b in calo_dataloader:\n",
        "    break"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3tQTdvbyVRxj",
        "colab_type": "text"
      },
      "source": [
        "## Training GAN\n",
        "###### ...is not a simple matter\n",
        "\n",
        "It depends on architecture, loss, instance noise, augmentation and even luck(recommend to take a look https://arxiv.org/pdf/1801.04406.pdf)\n",
        "\n",
        "\n",
        "In this notebook I have prepared some basic parts that you could use for your experiments."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YJEE5yLHVRxk",
        "colab_type": "text"
      },
      "source": [
        "### Three types of losses for GANs\n",
        "\n",
        "https://medium.com/@jonathan_hui/gan-what-is-wrong-with-the-gan-cost-function-6f594162ce01\n",
        "\n",
        "There were proposed numerous loss functions to train GANs. In this notebook we have implemented three the most popular choices(but feel free to try other variants!):\n",
        "\n",
        "### `KL`:\n",
        "\n",
        "\n",
        "$$\\mathcal{L}_g = \\log(1 - \\mathrm{discriminator}(\\mathrm{gen}))$$\n",
        "\n",
        "$$\\mathcal{L}_d = - \\log(\\mathrm{discriminator}(\\mathrm{gen})) - \\log(1 - \\mathrm{discriminator}(\\mathrm{real}))$$\n",
        "\n",
        "\n",
        "### `REVERSED_KL`\n",
        "\n",
        "$$\\mathcal{L}_g = - \\log(\\mathrm{discriminator}(\\mathrm{gen}))$$\n",
        "\n",
        "$$\\mathcal{L}_d = - \\log(\\mathrm{discriminator}(\\mathrm{gen})) - \\log(1 - \\mathrm{discriminator}(\\mathrm{real}))$$\n",
        "\n",
        "\n",
        "### `WASSERSTEIN`\n",
        "\n",
        "$$\\mathcal{L}_g = - \\mathrm{discriminator}(\\mathrm{gen})$$\n",
        "\n",
        "$$\\mathcal{L}_d = \\mathrm{discriminator}(\\mathrm{gen}) - \\mathrm{discriminator}(\\mathrm{real})$$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RbpAbe0KVRxk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "TASKS = ['KL', 'REVERSED_KL', 'WASSERSTEIN']\n",
        "\n",
        "TASK = 'WASSERSTEIN'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MNNcTOMoVRxm",
        "colab_type": "text"
      },
      "source": [
        "### Additional things for Wasserstein GAN\n",
        "\n",
        "To make `Wasserstein`-GAN works we suggest three options:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NI7nSFL1VRxn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "LIPSITZ_WEIGHTS = False\n",
        "clamp_lower, clamp_upper = -0.01, 0.01\n",
        "\n",
        "\n",
        "# https://arxiv.org/abs/1704.00028\n",
        "GRAD_PENALTY = True\n",
        "\n",
        "# https://arxiv.org/abs/1705.09367\n",
        "ZERO_CENTERED_GRAD_PENALTY = False\n",
        "\n",
        "XGB_PENALTY = True"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HRuAvibFVRxo",
        "colab_type": "text"
      },
      "source": [
        "#### Small hack that can speed-up training and improve generalization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eR2_t5PLVRxp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# https://arxiv.org/abs/1610.04490\n",
        "INSTANCE_NOISE = True\n",
        "\n",
        "def add_instance_noise(data, std=0.01):\n",
        "    return data + torch.distributions.Normal(0, std).sample(data.shape).to(device)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EJqPef3XgtVe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "INSTANCE_NOISE"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KYQzqvP3VRxq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class GANLosses(object):\n",
        "    def __init__(self, task, device):\n",
        "        self.TASK = task\n",
        "        self.device = device\n",
        "    \n",
        "    def g_loss(self, discrim_output):\n",
        "        eps = 1e-10\n",
        "        if self.TASK == 'KL': \n",
        "            loss = torch.log(1 - discrim_output + eps).mean()    \n",
        "        elif self.TASK == 'REVERSED_KL':\n",
        "            loss = - torch.log(discrim_output + eps).mean()\n",
        "        elif self.TASK == 'WASSERSTEIN':\n",
        "            loss = - discrim_output.mean()\n",
        "        return loss\n",
        "\n",
        "    def d_loss(self, discrim_output_gen, discrim_output_real):\n",
        "        eps = 1e-10\n",
        "        if self.TASK in ['KL', 'REVERSED_KL']: \n",
        "            loss = - torch.log(discrim_output_real + eps).mean() - torch.log(1 - discrim_output_gen + eps).mean()\n",
        "        elif self.TASK == 'WASSERSTEIN':\n",
        "            loss = - (discrim_output_real.mean() - discrim_output_gen.mean())\n",
        "        return loss\n",
        "\n",
        "    def calc_gradient_penalty(self, discriminator, data_gen, inputs_batch, inp_data, lambda_reg = .1):\n",
        "        alpha = torch.rand(inp_data.shape[0], 1).to(self.device)\n",
        "        dims_to_add = len(inp_data.size()) - 2\n",
        "        for i in range(dims_to_add):\n",
        "            alpha = alpha.unsqueeze(-1)\n",
        "        # alpha = alpha.expand(inp_data.size())\n",
        "\n",
        "        interpolates = (alpha * inp_data + ((1 - alpha) * data_gen)).to(self.device)\n",
        "\n",
        "        interpolates.requires_grad = True\n",
        "\n",
        "        disc_interpolates = discriminator(interpolates, inputs_batch)\n",
        "\n",
        "        gradients = torch.autograd.grad(outputs=disc_interpolates, inputs=interpolates,\n",
        "                                        grad_outputs=torch.ones(disc_interpolates.size()).to(self.device),\n",
        "                                        create_graph=True, retain_graph=True, only_inputs=True)[0]\n",
        "\n",
        "        gradient_penalty = ((gradients.norm(2, dim=1) - 1) ** 2).mean() * lambda_reg\n",
        "        return gradient_penalty\n",
        "    \n",
        "    def calc_zero_centered_GP(self, discriminator, data_gen, inputs_batch, inp_data, gamma_reg = .1):\n",
        "        \n",
        "        local_input = inp_data.clone().detach().requires_grad_(True)\n",
        "        disc_interpolates = discriminator(local_input, inputs_batch)\n",
        "        gradients = torch.autograd.grad(outputs=disc_interpolates, inputs=local_input,\n",
        "                                        grad_outputs=torch.ones(disc_interpolates.size()).to(self.device),\n",
        "                                        create_graph=True, retain_graph=True, only_inputs=True)[0]\n",
        "        return gamma_reg / 2 * (gradients.norm(2, dim=1) ** 2).mean() \n",
        "    \n",
        "    def calc_xgb_penalty(self, xgbmodel, data_gen, inputs_batch, inp_data, lambda_reg = .1):\n",
        "        \n",
        "        pool = nn.AvgPool2d(3)\n",
        "        x_gen = pool(data_gen)\n",
        "        x_gen = x_gen.view(len(x_gen),-1)\n",
        "        x_gen = torch.cat([x_gen, inputs_batch], dim=1).detach().cpu().numpy()\n",
        "        x_input = pool(inp_data)\n",
        "        x_input = x_input.view(len(x_input),-1)\n",
        "        x_input = torch.cat([x_input, inputs_batch], dim=1).detach().cpu().numpy()\n",
        "        X = np.concatenate([x_gen, x_input])\n",
        "        label = np.concatenate([np.ones(len(x_gen)), np.zeros(len(x_input))])\n",
        "        \n",
        "        Xtr, Xts, ytr, yts = train_test_split(X, label,\n",
        "                                                           test_size = 0.2, shuffle = True)\n",
        "        xgbmodel.fit(Xtr, ytr)\n",
        "        proba_gen = xgbmodel.predict_proba(Xts)[:,1]\n",
        "\n",
        "        xgb_penalty = ((proba_gen - yts) ** 2).mean() * lambda_reg\n",
        "        return xgb_penalty"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D00nMgVDVRxs",
        "colab_type": "text"
      },
      "source": [
        "## Defining discriminator"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M29-aaq5VRxv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class MyModelD(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(MyModelD, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 32, 3, padding=2)#1*30*30 --> 32*32*32 matrix\n",
        "        self.bn1 = nn.BatchNorm2d(32)\n",
        "        self.dropout = nn.Dropout(p=0.3)\n",
        "        self.conv2 = nn.Conv2d(32, 64, 2, stride=2)#--> 64 * 16 * 16\n",
        "        self.bn2 = nn.BatchNorm2d(64)\n",
        "        self.conv3 = nn.Conv2d(64, 128, 2, stride=2)#--> 128 * 8 * 8\n",
        "        self.conv4 = nn.Conv2d(128, 256, 2, stride=2)#--> 256 * 4 * 4\n",
        "        \n",
        "        # size\n",
        "        self.fc1 = nn.Linear(256*4*4 + 5, 512) \n",
        "        self.fc2 = nn.Linear(512, 128)\n",
        "        self.fc3 = nn.Linear(128, 64)\n",
        "        self.fc4 = nn.Linear(64, 1)\n",
        "        \n",
        "    def forward(self, EnergyDeposit, ParticleMomentum_ParticlePoint):\n",
        "        EnergyDeposit = self.dropout(F.leaky_relu(self.bn1(self.conv1(EnergyDeposit))))\n",
        "        EnergyDeposit = self.dropout(F.leaky_relu(self.bn2(self.conv2(EnergyDeposit))))\n",
        "        EnergyDeposit = F.leaky_relu(self.conv3(EnergyDeposit))\n",
        "        EnergyDeposit = F.leaky_relu(self.conv4(EnergyDeposit))\n",
        "        EnergyDeposit = EnergyDeposit.view(len(EnergyDeposit), -1)\n",
        "        \n",
        "        t = torch.cat([EnergyDeposit, ParticleMomentum_ParticlePoint], dim=1)\n",
        "        \n",
        "        t = F.leaky_relu(self.fc1(t))\n",
        "        t = F.leaky_relu(self.fc2(t))\n",
        "        t = F.leaky_relu(self.fc3(t))\n",
        "        \n",
        "        if TASK == 'WASSERSTEIN':\n",
        "            return self.fc4(t)\n",
        "        else:\n",
        "            return torch.sigmoid(self.fc4(t))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d_jF8oMFVRx0",
        "colab_type": "text"
      },
      "source": [
        "## Defining generator"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9pFrALgpVRx2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class MyModelGConvTranspose(nn.Module):\n",
        "    def __init__(self, z_dim):\n",
        "        self.z_dim = z_dim\n",
        "        super(MyModelGConvTranspose, self).__init__()\n",
        "        self.fc1 = nn.Linear(self.z_dim + 2 + 3, 64)\n",
        "        self.fc2 = nn.Linear(64, 128)\n",
        "        self.fc3 = nn.Linear(128, 512)\n",
        "        self.fc4 = nn.Linear(512, 2048)\n",
        "        \n",
        "        \n",
        "        self.conv1 = nn.ConvTranspose2d(512, 256, 2, stride=2, output_padding=0)#-->256 * 4 * 4\n",
        "        self.bn1 = nn.BatchNorm2d(256)\n",
        "        self.conv2 = nn.ConvTranspose2d(256, 128, 2, stride=2)#-->128 * 8 * 8\n",
        "        self.bn2 = nn.BatchNorm2d(128)\n",
        "        self.conv3 = nn.ConvTranspose2d(128, 64, 2, stride=2)#--> 64 * 16 * 16\n",
        "        self.bn3 = nn.BatchNorm2d(64)\n",
        "        self.conv4 = nn.ConvTranspose2d(64, 32, 2, stride=2)#--> 32 * 32 * 32\n",
        "        self.bn4 = nn.BatchNorm2d(32)\n",
        "        self.conv5 = nn.ConvTranspose2d(32, 1, 1, stride=1, padding=1)#--> 1 * 30 * 30\n",
        "        \n",
        "        \n",
        "    def forward(self, z, ParticleMomentum_ParticlePoint):\n",
        "        x = F.leaky_relu(self.fc1(\n",
        "            torch.cat([z, ParticleMomentum_ParticlePoint], dim=1)\n",
        "        ))\n",
        "        x = F.leaky_relu(self.fc2(x))\n",
        "        x = F.leaky_relu(self.fc3(x))\n",
        "        x = F.leaky_relu(self.fc4(x))\n",
        "        \n",
        "        \n",
        "        EnergyDeposit = x.view(-1, 512, 2, 2)\n",
        "        \n",
        "        EnergyDeposit = F.leaky_relu(self.bn1(self.conv1(EnergyDeposit)))\n",
        "        EnergyDeposit = F.leaky_relu(self.bn2(self.conv2(EnergyDeposit)))\n",
        "        EnergyDeposit = F.leaky_relu(self.bn3(self.conv3(EnergyDeposit)))\n",
        "        EnergyDeposit = F.leaky_relu(self.bn4(self.conv4(EnergyDeposit)))\n",
        "        EnergyDeposit = self.conv5(EnergyDeposit)\n",
        "\n",
        "        return EnergyDeposit"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "krbTl5o2VRx3",
        "colab_type": "text"
      },
      "source": [
        "## Check our models on one batch "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yVDh76scVRx4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "NOISE_DIM = 10\n",
        "\n",
        "#discriminator = ModelD().to(device)\n",
        "#generator = ModelGConvTranspose(z_dim=NOISE_DIM).to(device)\n",
        "discriminator = MyModelD().to(device)\n",
        "generator = MyModelGConvTranspose(z_dim=NOISE_DIM).to(device)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-KCYDLf-VRx6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "EnergyDeposit_b, ParticleMomentum_b, ParticlePoint_b = EnergyDeposit_b.to(device), \\\n",
        "                                                       ParticleMomentum_b.to(device), \\\n",
        "                                                       ParticlePoint_b.to(device)\n",
        "ParticleMomentum_ParticlePoint_b = torch.cat([ParticleMomentum_b.to(device), ParticlePoint_b.to(device)], dim=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kylQl8i2VRx8",
        "colab_type": "code",
        "outputId": "0cb35c69-81a1-4dde-b3ae-8d7531b4226a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "EnergyDeposit_b.shape"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([128, 1, 30, 30])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J0jeDzq5VRx-",
        "colab_type": "code",
        "outputId": "5f74213d-3a1e-4a38-c970-96172c467ef6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "discriminator(EnergyDeposit_b, ParticleMomentum_ParticlePoint_b).shape"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([128, 1])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MFY5BhfKVRyO",
        "colab_type": "code",
        "outputId": "af18ac10-a508-4f9e-d4cb-41f7c1f4219b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "noise = torch.randn(len(EnergyDeposit_b), NOISE_DIM).to(device)\n",
        "generator(noise, ParticleMomentum_ParticlePoint_b).shape"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([128, 1, 30, 30])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QFx2UMR4VRxx",
        "colab_type": "text"
      },
      "source": [
        "## Pre-learning XGBoost"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-k1JtQ6Aj_Io",
        "colab_type": "text"
      },
      "source": [
        "Tune hyper parameter"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nxNKmgFve5ct",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def objective(trial):\n",
        "    learning_rate = trial.suggest_loguniform('learning_rate', 0.001, 0.1)\n",
        "    max_depth = trial.suggest_int('max_depth', 5, 15)\n",
        "    gamma = trial.suggest_uniform('gamma', 0.5, 1)\n",
        "    subsample = trial.suggest_discrete_uniform('subsample', 0.5, 0.9, 0.1)\n",
        "    reg_lambda = trial.suggest_discrete_uniform('reg_lambda', 0.5, 1, 0.25)\n",
        "    n_folds = 3\n",
        "    score = 0.0\n",
        "    test_size = float(1/n_folds)\n",
        "    for i in range(n_folds):        \n",
        "        \n",
        "            pool = nn.AvgPool2d(3)\n",
        "            x_gen = pool(EnergyDeposit.to(device))\n",
        "            x_gen = x_gen.view(len(x_gen),-1)\n",
        "            x_gen = torch.cat([x_gen, ParticleMomentum_ParticlePoint.to(device)], dim=1).detach().cpu().numpy()\n",
        "            #x_input = pool(inp_data)\n",
        "            #x_input = x_input.view(len(x_input),-1)\n",
        "            x_input = torch.randn(len(x_gen), 10*10).to(device)\n",
        "            x_input = torch.cat([x_input, ParticleMomentum_ParticlePoint.to(device)], dim=1).detach().cpu().numpy()\n",
        "            X = np.concatenate([x_gen, x_input])\n",
        "            label = np.concatenate([np.ones(len(x_gen)), np.zeros(len(x_input))])\n",
        "            \n",
        "            Xtr, Xts, ytr, yts = train_test_split(X, label,\n",
        "                                                                  test_size = test_size, shuffle = True)\n",
        "            \n",
        "            \n",
        "            model = xgb.XGBClassifier(objective = 'binary:logistic', learning_rate = learning_rate, max_depth = max_depth, \n",
        "                                  gamma = gamma, subsample = subsample, reg_lambda = reg_lambda,\n",
        "                                  n_jobs = -1, eval_metric = 'auc', eta = 0.3)\n",
        "\n",
        "            model.fit(Xtr, ytr, verbose = True)\n",
        "            predictions = model.predict_proba(Xts)[:,1]\n",
        "\n",
        "            score_tmp = ((predictions - yts) ** 2).mean()/len(predictions)*1.e6\n",
        "            print(score_tmp)\n",
        "            score += score_tmp\n",
        "\n",
        "            \n",
        "    score /= n_folds\n",
        "    return score"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CLon1oKGmRzJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "study = optuna.create_study()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z6T-Ly7_mPMJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#study.optimize(objective, n_trials=50)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-gB5fKn6fpUD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "study.best_params"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MD8wQvzgkFsM",
        "colab_type": "text"
      },
      "source": [
        "Train the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ktHuuGmPv7kS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#gamma = 0.7068765415040321\n",
        "#learning_rate = 0.09935458780449181\n",
        "#max_depth = 9\n",
        "#reg_lambda = 0.75\n",
        "#subsample = 0.7\n",
        "gamma = 0.7960376699084336\n",
        "learning_rate = 0.0989074596700562\n",
        "max_depth = 11\n",
        "reg_lambda = 0.5\n",
        "subsample = 0.5"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TjJQdEImvJal",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "xgbmodel = xgb.XGBClassifier(objective = 'binary:logistic', learning_rate = learning_rate, max_depth = max_depth, \n",
        "                                  gamma = gamma, subsample = subsample, reg_lambda = reg_lambda,\n",
        "                                  n_jobs = -1, eval_metric = 'auc', eta = 0.3)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OAIh7QYqvqyt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pool = nn.AvgPool2d(3)\n",
        "x_gen = pool(EnergyDeposit.to(device))\n",
        "x_gen = x_gen.view(len(x_gen),-1)\n",
        "x_gen = torch.cat([x_gen, ParticleMomentum_ParticlePoint.to(device)], dim=1).detach().cpu().numpy()\n",
        "\n",
        "x_input = torch.randn(len(x_gen), 10*10).to(device)\n",
        "x_input = torch.cat([x_input, ParticleMomentum_ParticlePoint.to(device)], dim=1).detach().cpu().numpy()\n",
        "X = np.concatenate([x_gen, x_input])\n",
        "label = np.concatenate([np.ones(len(x_gen)), np.zeros(len(x_input))])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ynp5w-vHvaRv",
        "colab_type": "code",
        "outputId": "8d4313b4-d95e-46ac-c4b1-959f4c34fcf7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        }
      },
      "source": [
        "xgbmodel.fit(X, label, verbose = True)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
              "              colsample_bynode=1, colsample_bytree=1, eta=0.3,\n",
              "              eval_metric='auc', gamma=0.7960376699084336,\n",
              "              learning_rate=0.0989074596700562, max_delta_step=0, max_depth=11,\n",
              "              min_child_weight=1, missing=None, n_estimators=100, n_jobs=-1,\n",
              "              nthread=None, objective='binary:logistic', random_state=0,\n",
              "              reg_alpha=0, reg_lambda=0.5, scale_pos_weight=1, seed=None,\n",
              "              silent=None, subsample=0.5, verbosity=1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8SlqNwv2VRyR",
        "colab_type": "text"
      },
      "source": [
        "## Defining optimiser"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dVMmSHAuVRyW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "learning_rate_dis = 1e-3\n",
        "learning_rate_gen = 1e-3\n",
        "\n",
        "g_optimizer = optim.Adam(generator.parameters(), lr=learning_rate_gen, weight_decay=1e-6)\n",
        "d_optimizer = optim.SGD(discriminator.parameters(), lr=learning_rate_dis, weight_decay=1e-6)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YANUNU4UVRyb",
        "colab_type": "text"
      },
      "source": [
        "## Load scores"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j7D2aqKEVRyc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from prd_score import compute_prd, compute_prd_from_embedding, _prd_to_f_beta\n",
        "from sklearn.metrics import auc"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1FW2ZX0gVRyd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "def run_training(epochs):\n",
        "\n",
        "    # ===========================\n",
        "    # IMPORTANT PARAMETER:\n",
        "    # Number of D updates per G update\n",
        "    # ===========================\n",
        "    k_d, k_g = 5, 1 #<--10, 1?\n",
        "    #k_d, k_g = 10, 1\n",
        "\n",
        "    gan_losses = GANLosses(TASK, device)\n",
        "    dis_epoch_loss = []\n",
        "    gen_epoch_loss = []\n",
        "    predictions_dis = []\n",
        "    predictions_gen = []\n",
        "    prd_auc = []  \n",
        "    for epoch in tqdm(range(epochs)):\n",
        "        first = True\n",
        "        \n",
        "        for EnergyDeposit_b, ParticleMomentum_b, ParticlePoint_b in calo_dataloader:\n",
        "            EnergyDeposit_b, ParticleMomentum_b, ParticlePoint_b = EnergyDeposit_b.to(device), \\\n",
        "                                                                   ParticleMomentum_b.to(device), \\\n",
        "                                                                   ParticlePoint_b.to(device)\n",
        "            ParticleMomentum_ParticlePoint_b = torch.cat([ParticleMomentum_b.to(device), ParticlePoint_b.to(device)], dim=1)\n",
        "            if first:\n",
        "                noise = torch.randn(len(EnergyDeposit_b), NOISE_DIM).to(device)\n",
        "                EnergyDeposit_gen = generator(noise, ParticleMomentum_ParticlePoint_b)\n",
        "                predictions_dis.append(\n",
        "                    list(discriminator(EnergyDeposit_b, ParticleMomentum_ParticlePoint_b).detach().cpu().numpy().ravel())\n",
        "                )\n",
        "\n",
        "                predictions_gen.append(\n",
        "                    list(discriminator(EnergyDeposit_gen, ParticleMomentum_ParticlePoint_b).detach().cpu().numpy().ravel())\n",
        "                )\n",
        "                \n",
        "            # Optimize D\n",
        "            for _ in range(k_d):\n",
        "                noise = torch.randn(len(EnergyDeposit_b), NOISE_DIM).to(device)\n",
        "                EnergyDeposit_gen = generator(noise, ParticleMomentum_ParticlePoint_b)\n",
        "    \n",
        "                if INSTANCE_NOISE:\n",
        "                    EnergyDeposit_b = add_instance_noise(EnergyDeposit_b)\n",
        "                    EnergyDeposit_gen = add_instance_noise(EnergyDeposit_gen)\n",
        "                    \n",
        "                loss = gan_losses.d_loss(discriminator(EnergyDeposit_gen, ParticleMomentum_ParticlePoint_b),\n",
        "                                         discriminator(EnergyDeposit_b, ParticleMomentum_ParticlePoint_b))\n",
        "                if GRAD_PENALTY:\n",
        "                    grad_penalty = gan_losses.calc_gradient_penalty(discriminator,\n",
        "                                                                    EnergyDeposit_gen.data,\n",
        "                                                                    ParticleMomentum_ParticlePoint_b,\n",
        "                                                                    EnergyDeposit_b.data)\n",
        "                    loss += grad_penalty\n",
        "                    \n",
        "                elif ZERO_CENTERED_GRAD_PENALTY:\n",
        "                    grad_penalty = gan_losses.calc_zero_centered_GP(discriminator,\n",
        "                                                                    EnergyDeposit_gen.data,\n",
        "                                                                    ParticleMomentum_ParticlePoint_b,\n",
        "                                                                    EnergyDeposit_b.data)\n",
        "                    loss -= grad_penalty\n",
        "                if XGB_PENALTY:\n",
        "                    xgb_penalty = gan_losses.calc_xgb_penalty(xgbmodel,\n",
        "                                                                    EnergyDeposit_gen.data,\n",
        "                                                                    ParticleMomentum_ParticlePoint_b,\n",
        "                                                                    EnergyDeposit_b.data)\n",
        "                    loss += xgb_penalty\n",
        "\n",
        "                d_optimizer.zero_grad()\n",
        "                loss.backward()\n",
        "                d_optimizer.step()\n",
        "                if LIPSITZ_WEIGHTS:                    \n",
        "                    [p.data.clamp_(clamp_lower, clamp_upper) for p in discriminator.parameters()]\n",
        "\n",
        "            dis_epoch_loss.append(loss.item())\n",
        "\n",
        "            # Optimize G\n",
        "            for _ in range(k_g):\n",
        "                noise = torch.randn(len(EnergyDeposit_b), NOISE_DIM).to(device)\n",
        "                EnergyDeposit_gen = generator(noise, ParticleMomentum_ParticlePoint_b)\n",
        "                \n",
        "                if INSTANCE_NOISE:\n",
        "                    EnergyDeposit_b = add_instance_noise(EnergyDeposit_b)\n",
        "                    EnergyDeposit_gen = add_instance_noise(EnergyDeposit_gen)\n",
        "                \n",
        "                loss = gan_losses.g_loss(discriminator(EnergyDeposit_gen, ParticleMomentum_ParticlePoint_b))\n",
        "                g_optimizer.zero_grad()\n",
        "                loss.backward()\n",
        "                g_optimizer.step()\n",
        "                \n",
        "            gen_epoch_loss.append(loss.item())\n",
        "            if first:\n",
        "                precision, recall = compute_prd_from_embedding(\n",
        "                    EnergyDeposit_gen.detach().cpu().numpy().reshape(BATCH_SIZE, -1), \n",
        "                    EnergyDeposit_b.detach().cpu().numpy().reshape(BATCH_SIZE, -1),\n",
        "                    num_clusters=30,\n",
        "                    num_runs=100)\n",
        "                prd_auc.append(auc(precision, recall))\n",
        "                first = False\n",
        "        \n",
        "        clear_output()\n",
        "        plt.figure(figsize=(12, 12))\n",
        "        plt.plot(dis_epoch_loss, label='dis_epoch_loss')\n",
        "        plt.plot(gen_epoch_loss, label='gen_epoch_loss')\n",
        "        plt.legend()\n",
        "        plt.show()\n",
        "        \n",
        "        plt.figure(figsize=(12, 12))\n",
        "        plt.hist(predictions_dis[-1], bins=100, label='dis_epoch_loss')\n",
        "        plt.hist(predictions_gen[-1], bins=100, label='gen_epoch_loss')\n",
        "        plt.legend()\n",
        "        plt.show()\n",
        "        print(np.mean(predictions_dis[-1]), np.mean(predictions_gen[-1]))\n",
        "        \n",
        "        plt.figure(figsize=(12, 12))\n",
        "        plt.plot(prd_auc, label='prd_auc')\n",
        "        plt.plot()\n",
        "        plt.legend()\n",
        "        plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "AXbJiRxEVRyf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "run_training(500)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l9l9N0yFVRyh",
        "colab_type": "text"
      },
      "source": [
        "#### Transfer generator on CPU:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NzGQims9VRyi",
        "colab_type": "code",
        "outputId": "a2acd5ff-bd15-490d-d1ad-9d506d428627",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        }
      },
      "source": [
        "#generator_cpu = ModelGConvTranspose(z_dim=NOISE_DIM)\n",
        "generator_cpu = MyModelGConvTranspose(z_dim=NOISE_DIM)\n",
        "generator_cpu.load_state_dict(generator.state_dict())\n",
        "generator_cpu.eval()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MyModelGConvTranspose(\n",
              "  (fc1): Linear(in_features=15, out_features=64, bias=True)\n",
              "  (fc2): Linear(in_features=64, out_features=128, bias=True)\n",
              "  (fc3): Linear(in_features=128, out_features=512, bias=True)\n",
              "  (fc4): Linear(in_features=512, out_features=4096, bias=True)\n",
              "  (conv2): ConvTranspose2d(256, 128, kernel_size=(2, 2), stride=(2, 2))\n",
              "  (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (conv3): ConvTranspose2d(128, 64, kernel_size=(2, 2), stride=(2, 2))\n",
              "  (bn3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (conv4): ConvTranspose2d(64, 32, kernel_size=(2, 2), stride=(2, 2))\n",
              "  (bn4): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (conv5): ConvTranspose2d(32, 1, kernel_size=(1, 1), stride=(1, 1), padding=(1, 1))\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3EgnJkioVRyk",
        "colab_type": "code",
        "outputId": "f39ff22e-4255-4166-c226-318535e21620",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        }
      },
      "source": [
        "discriminator_cpu = MyModelD()\n",
        "discriminator_cpu.load_state_dict(discriminator.state_dict())\n",
        "discriminator_cpu.eval()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MyModelD(\n",
              "  (conv1): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2))\n",
              "  (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (dropout): Dropout(p=0.3)\n",
              "  (conv2): Conv2d(32, 64, kernel_size=(2, 2), stride=(2, 2))\n",
              "  (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (conv3): Conv2d(64, 128, kernel_size=(2, 2), stride=(2, 2))\n",
              "  (conv4): Conv2d(128, 256, kernel_size=(2, 2), stride=(2, 2))\n",
              "  (fc1): Linear(in_features=4101, out_features=512, bias=True)\n",
              "  (fc2): Linear(in_features=512, out_features=128, bias=True)\n",
              "  (fc3): Linear(in_features=128, out_features=64, bias=True)\n",
              "  (fc4): Linear(in_features=64, out_features=1, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1mQB7lxJVRyl",
        "colab_type": "text"
      },
      "source": [
        "## Making predictions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XJiiW1dLVRym",
        "colab_type": "text"
      },
      "source": [
        "#### Validation predictions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "EFU6vwSAVRym",
        "colab_type": "code",
        "outputId": "79db94e3-2a1f-4008-d8d4-352586afe63f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "data_val = np.load(val_data_path, allow_pickle=True)\n",
        "ParticleMomentum_val = torch.tensor(data_val['ParticleMomentum']).float()\n",
        "ParticlePoint_val = torch.tensor(data_val['ParticlePoint'][:, :2]).float()\n",
        "ParticleMomentum_ParticlePoint_val = torch.cat([ParticleMomentum_val, ParticlePoint_val], dim=1)\n",
        "calo_dataset_val = utils.TensorDataset(ParticleMomentum_ParticlePoint_val)\n",
        "calo_dataloader_val = torch.utils.data.DataLoader(calo_dataset_val, batch_size=1024, shuffle=False)\n",
        "\n",
        "with torch.no_grad():\n",
        "    EnergyDeposit_val = []\n",
        "    for ParticleMomentum_ParticlePoint_val_batch in tqdm(calo_dataloader_val):\n",
        "        noise = torch.randn(len(ParticleMomentum_ParticlePoint_val_batch[0]), NOISE_DIM)\n",
        "        EnergyDeposit_val_batch = generator_cpu(noise, ParticleMomentum_ParticlePoint_val_batch[0]).detach().numpy()\n",
        "        EnergyDeposit_val.append(EnergyDeposit_val_batch)\n",
        "    np.savez_compressed('./data_val_prediction.npz', \n",
        "                        EnergyDeposit=np.concatenate(EnergyDeposit_val, axis=0))\n",
        "\n",
        "    del EnergyDeposit_val\n",
        "del data_val; del ParticleMomentum_val; del ParticlePoint_val; del ParticleMomentum_ParticlePoint_val;\n",
        "del calo_dataset_val; calo_dataloader_val"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 50/50 [00:31<00:00,  1.60it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch.utils.data.dataloader.DataLoader at 0x7ff46639cac8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_GcleiryVRyo",
        "colab_type": "text"
      },
      "source": [
        "#### Test predictions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oegsyw-GVRyp",
        "colab_type": "code",
        "outputId": "8896bf74-df11-4a26-f553-93febcaa0f31",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "data_test = np.load(test_data_path, allow_pickle=True)\n",
        "ParticleMomentum_test = torch.tensor(data_test['ParticleMomentum']).float()\n",
        "ParticlePoint_test = torch.tensor(data_test['ParticlePoint'][:, :2]).float()\n",
        "ParticleMomentum_ParticlePoint_test = torch.cat([ParticleMomentum_test, ParticlePoint_test], dim=1)\n",
        "calo_dataset_test = utils.TensorDataset(ParticleMomentum_ParticlePoint_test)\n",
        "calo_dataloader_test = torch.utils.data.DataLoader(calo_dataset_test, batch_size=1024, shuffle=False)\n",
        "\n",
        "with torch.no_grad():\n",
        "    EnergyDeposit_test = []\n",
        "    for ParticleMomentum_ParticlePoint_test_batch in tqdm(calo_dataloader_test):\n",
        "        noise = torch.randn(len(ParticleMomentum_ParticlePoint_test_batch[0]), NOISE_DIM)\n",
        "        EnergyDeposit_test_batch = generator_cpu(noise, ParticleMomentum_ParticlePoint_test_batch[0]).detach().numpy()\n",
        "        EnergyDeposit_test.append(EnergyDeposit_test_batch)\n",
        "    np.savez_compressed('./data_test_prediction.npz', \n",
        "                        EnergyDeposit=np.concatenate(EnergyDeposit_test, axis=0))\n",
        "\n",
        "    del EnergyDeposit_test\n",
        "del data_test; del ParticleMomentum_test; del ParticlePoint_test; del ParticleMomentum_ParticlePoint_test;\n",
        "del calo_dataset_test; calo_dataloader_test"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 49/49 [00:30<00:00,  1.96it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch.utils.data.dataloader.DataLoader at 0x7ff45010a748>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B8DpeylvVRyq",
        "colab_type": "text"
      },
      "source": [
        "## `zip-zip` files together"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xCU7bGW6VRyr",
        "colab_type": "code",
        "outputId": "53e4834f-0037-46e7-b68d-221fa9648a22",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        }
      },
      "source": [
        "!zip solution.zip data_val_prediction.npz data_test_prediction.npz"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  adding: data_val_prediction.npz (deflated 0%)\n",
            "  adding: data_test_prediction.npz (deflated 0%)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-j89fzh9VRyt",
        "colab_type": "code",
        "outputId": "0e537a77-c41b-4041-b5b9-b800cca169c9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from IPython.display import FileLink\n",
        "FileLink('./solution.zip')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<a href='./solution.zip' target='_blank'>./solution.zip</a><br>"
            ],
            "text/plain": [
              "/content/solution.zip"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ALlu5FnAVRyv",
        "colab_type": "code",
        "outputId": "86dbc7ec-8df6-45bd-d32a-33c3ff9c2f20",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        }
      },
      "source": [
        "torch.save(generator_cpu.state_dict(), 'generator_dict.model')\n",
        "torch.save(generator_cpu, 'generator.model')\n",
        "torch.save(discriminator_cpu.state_dict(), 'discriminator_dict.model')\n",
        "torch.save(discriminator_cpu, 'discriminator.model')\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:256: UserWarning:\n",
            "\n",
            "Couldn't retrieve source code for container of type MyModelGConvTranspose. It won't be checked for correctness upon loading.\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:256: UserWarning:\n",
            "\n",
            "Couldn't retrieve source code for container of type MyModelD. It won't be checked for correctness upon loading.\n",
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MIpsJqt2LOfy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "modelname = \"XGB\"\n",
        "modeldir=\"./\"\n",
        "joblib.dump(model, modeldir + '/' + modelname + \".pkl\")\n",
        "xgbfir.saveXgbFI(model, feature_names=Xtr.columns, OutputXlsxFile= modelname + '.xlsx')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-VZdA5LmVRyx",
        "colab_type": "text"
      },
      "source": [
        "# A few words about metrics"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4AVY2qIEVRyy",
        "colab_type": "text"
      },
      "source": [
        "### Lets generate some fake data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9RsF5KDRVRyz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "noise = torch.randn(len(ParticleMomentum), NOISE_DIM)\n",
        "ParticleMomentum_ParticlePoint = torch.cat([ParticleMomentum, \n",
        "                                            ParticlePoint], dim=1)\n",
        "EnergyDeposit_gen = generator_cpu(noise, ParticleMomentum_ParticlePoint)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eB2L2fubVRy0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "EnergyDeposit_gen = EnergyDeposit_gen.detach().cpu().numpy().reshape(-1, 30, 30)\n",
        "EnergyDeposit = EnergyDeposit.detach().cpu().numpy().reshape(-1, 30, 30)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W_lXgkCoVRy3",
        "colab_type": "text"
      },
      "source": [
        "#### Plot one image"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zV4iIH1BVRy3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.figure()\n",
        "plt.imshow(EnergyDeposit_gen[0])\n",
        "plt.colorbar()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vfXLgAbJVRy4",
        "colab_type": "text"
      },
      "source": [
        "## Calculate PRD score between these batch "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hjgAhZnPVRy4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Regressor(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Regressor, self).__init__()\n",
        "        self.batchnorm0 = nn.BatchNorm2d(1)\n",
        "        self.conv1 = nn.Conv2d(1, 16, 2, stride=2)\n",
        "        self.batchnorm1 = nn.BatchNorm2d(16)\n",
        "        self.conv2 = nn.Conv2d(16, 32, 2, stride=2)\n",
        "        self.batchnorm2 = nn.BatchNorm2d(32)\n",
        "        self.conv3 = nn.Conv2d(32, 64, 2, stride=2)\n",
        "        self.batchnorm3 = nn.BatchNorm2d(64)\n",
        "        self.conv4 = nn.Conv2d(64, 64, 2)\n",
        "        \n",
        "        self.dropout = nn.Dropout(p=0.3)\n",
        "        \n",
        "        self.fc1 = nn.Linear(256, 256) \n",
        "        self.batchnorm4 = nn.BatchNorm1d(256)\n",
        "        self.fc2 = nn.Linear(256, 128)\n",
        "        self.fc3 = nn.Linear(128, 64)\n",
        "        self.fc4 = nn.Linear(64, 2 + 3)\n",
        "        self.fc5 = nn.Linear(64, 1)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        x = self.batchnorm0(self.dropout(x))\n",
        "        x = self.batchnorm1(self.dropout(F.relu(self.conv1(x))))\n",
        "        x = self.batchnorm2(F.relu(self.conv2(x)))\n",
        "        x = self.batchnorm3(F.relu(self.conv3(x)))\n",
        "        x = F.relu(self.conv4(x)) # 64, 5, 5\n",
        "        x = x.view(len(x), -1)\n",
        "        x = self.dropout(x)\n",
        "        x = self.batchnorm4(self.dropout(F.relu(self.fc1(x))))\n",
        "        x = F.leaky_relu(self.fc2(x))\n",
        "        x = torch.tanh(self.fc3(x))\n",
        "        return self.fc4(x), self.fc5(x)\n",
        "    \n",
        "    def get_encoding(self, x):\n",
        "        x = self.batchnorm0(self.dropout(x))\n",
        "        x = self.batchnorm1(self.dropout(F.relu(self.conv1(x))))\n",
        "        x = self.batchnorm2(F.relu(self.conv2(x)))\n",
        "        x = self.batchnorm3(F.relu(self.conv3(x)))\n",
        "        x = F.relu(self.conv4(x)) # 64, 5, 5\n",
        "        x = x.view(len(x), -1)\n",
        "        x = self.dropout(x)\n",
        "        x = self.batchnorm4(self.dropout(F.relu(self.fc1(x))))\n",
        "        x = F.leaky_relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x\n",
        "    \n",
        "\n",
        "def load_embedder(path):\n",
        "    embedder = torch.load(path)\n",
        "    embedder.eval()\n",
        "    return embedder\n",
        "\n",
        "embedder = load_embedder('./embedder.tp')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wNJb6CmXVRy5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data_real = embedder.get_encoding(torch.tensor(EnergyDeposit).float().view(-1, 1, 30, 30)).detach().numpy()\n",
        "data_fake = embedder.get_encoding(torch.tensor(EnergyDeposit_gen).float().view(-1, 1, 30, 30)).detach().numpy()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P8LKJW9dVRy6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def plot_pr_aucs(precisions, recalls):\n",
        "    plt.figure(figsize=(12, 12))\n",
        "    pr_aucs = []\n",
        "    for i in range(len(recalls)):\n",
        "        plt.step(recalls[i], precisions[i], color='b', alpha=0.2,  label='PR-AUC={}'.format(auc(precisions[i], recalls[i])))\n",
        "        pr_aucs.append(auc(precisions[i], recalls[i]))\n",
        "    plt.step(np.mean(recalls, axis=0), np.mean(precisions, axis=0), color='r', alpha=1,  label='average')\n",
        "    plt.fill_between(np.mean(recalls, axis=0), \n",
        "                     np.mean(precisions, axis=0) - np.std(precisions, axis=0) * 3,\n",
        "                     np.mean(precisions, axis=0) + np.std(precisions, axis=0) * 3, color='g', alpha=0.2,  label='std')\n",
        "\n",
        "    plt.xlabel('Recall')\n",
        "    plt.ylabel('Precision')\n",
        "\n",
        "    # plt.ylim([0.0, 1.05])\n",
        "    # plt.xlim([0.0, 1.0])\n",
        "    print(np.mean(pr_aucs), np.std(pr_aucs))\n",
        "    plt.legend()\n",
        "    \n",
        "    return pr_aucs\n",
        "\n",
        "def calc_pr_rec(data_real, data_fake, num_clusters=20, num_runs=10, NUM_RUNS=10):\n",
        "    precisions = []\n",
        "    recalls = []\n",
        "    for i in tqdm(range(NUM_RUNS)):\n",
        "        precision, recall = compute_prd_from_embedding(data_real, data_fake, num_clusters=num_clusters, num_runs=num_runs)\n",
        "        precisions.append(precision)\n",
        "        recalls.append(recall)\n",
        "    return precisions, recalls"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "owOYkHT3VRzA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "precisions, recalls = calc_pr_rec(data_real, data_fake, num_clusters=100, num_runs=20)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xltnXrfXVRzC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pr_aucs = plot_pr_aucs(precisions, recalls)\n",
        "plt.title('Num_clusters={}, num_runs={}, first third'.format(100, 20))\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kxQ5gdaeVRzD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pr_aucs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "133F5u3xVRzE",
        "colab_type": "text"
      },
      "source": [
        "## Physical metrics"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X3Q6Oek5VRzE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.lines as mlines\n",
        "def newline(p1, p2):\n",
        "    ax = plt.gca()\n",
        "    xmin, xmax = ax.get_xbound()\n",
        "\n",
        "    if(p2[0] == p1[0]):\n",
        "        xmin = xmax = p1[0]\n",
        "        ymin, ymax = ax.get_ybound()\n",
        "    else:\n",
        "        ymax = p1[1]+(p2[1]-p1[1])/(p2[0]-p1[0])*(xmax-p1[0])\n",
        "        ymin = p1[1]+(p2[1]-p1[1])/(p2[0]-p1[0])*(xmin-p1[0])\n",
        "\n",
        "    l = mlines.Line2D([xmin,xmax], [ymin,ymax])\n",
        "    ax.add_line(l)\n",
        "    return l\n",
        "\n",
        "def plot_axes_for_shower(ecal, point, p):\n",
        "    x = np.linspace(-14.5, 14.5, 30)\n",
        "    y = np.linspace(-14.5, 14.5, 30)\n",
        "\n",
        "    xx, yy = np.meshgrid(x, y)\n",
        "    zoff = 25.\n",
        "    ipic = 3\n",
        "    orth = np.array([-p[1], p[0]])\n",
        "\n",
        "    pref = point[:2] + p[:2] * zoff / p[2]\n",
        "\n",
        "    p1 = pref - 10 * p[:2]\n",
        "    p2 = pref + 10 * p[:2]\n",
        "    p3 = pref - 10 * orth\n",
        "    p4 = pref + 10 * orth\n",
        "\n",
        "    plt.contourf(xx, yy, np.log(ecal + 1), cmap=plt.cm.inferno)\n",
        "    newline(p1, p2)\n",
        "    newline(p3, p4)\n",
        "    plt.colorbar()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "udb-1KK4VRzF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "idx = 2\n",
        "plot_axes_for_shower(EnergyDeposit[idx], point=ParticlePoint[idx].detach().numpy(),\n",
        "                     p=ParticleMomentum[idx].detach().numpy())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9GnxeqR0VRzG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from calogan_metrics import get_assymetry, get_shower_width, get_sparsity_level"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GUGYVroNVRzG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "assym = get_assymetry(EnergyDeposit, ParticleMomentum.detach().numpy(), ParticlePoint.detach().numpy(), orthog=False)\n",
        "assym_ortho = get_assymetry(EnergyDeposit, ParticleMomentum.detach().numpy(), ParticlePoint.detach().numpy(), orthog=True)\n",
        "sh_width = get_shower_width(EnergyDeposit, ParticleMomentum.detach().numpy(), ParticlePoint.detach().numpy(), orthog=False)\n",
        "sh_width_ortho = get_shower_width(EnergyDeposit, ParticleMomentum.detach().numpy(), ParticlePoint.detach().numpy(), orthog=True)\n",
        "sparsity_level = get_sparsity_level(EnergyDeposit)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q5xv3LSQVRzH",
        "colab_type": "text"
      },
      "source": [
        "## Longitudual cluster asymmetry"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zF-C9SZKVRzH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sns.set(font_scale=2)\n",
        "plt.hist(assym, bins=50, range=[-1, 1], color='red', alpha=0.3, normed=True, label='MC');\n",
        "plt.xlabel('Longitudual cluster asymmetry')\n",
        "plt.legend(loc='best')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iIRRXvXRVRzI",
        "colab_type": "text"
      },
      "source": [
        "## Transverse cluster asymmetry"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rzFWt3vaVRzI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sns.set(font_scale=2)\n",
        "plt.hist(assym_ortho, bins=50, range=[-1, 1], color='red', alpha=0.3, normed=True, label='MC');\n",
        "plt.xlabel('Transverse cluster asymmetry')\n",
        "plt.legend(loc='best')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GRS1RhPNVRzJ",
        "colab_type": "text"
      },
      "source": [
        "## Cluster longitudual width"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SEstLTbfVRzJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.hist(sh_width, bins=50, range=[0, 15], normed=True, alpha=0.3, color='red', label='MC');\n",
        "plt.title('Shower longitudial width')\n",
        "plt.legend(loc='best')\n",
        "plt.xlabel('Cluster longitudual width [cm]')\n",
        "plt.ylabel('Arbitrary units')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1rpYu1blVRzK",
        "colab_type": "text"
      },
      "source": [
        "## Cluster trasverse width"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e1Ftd9uqVRzK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.hist(sh_width_ortho, bins=50, range=[0,10], normed=True, alpha=0.3, color='blue', label='MC');\n",
        "#plt.title('Shower transverse width')\n",
        "plt.legend(loc='best')\n",
        "plt.xlabel('Cluster trasverse width [cm]')\n",
        "plt.ylabel('Arbitrary units')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qF2_ZY_5VRzL",
        "colab_type": "text"
      },
      "source": [
        "## Sparsity"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Oi0Zt5LsVRzL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "alphas = np.log(np.logspace(-5, -1, 20))\n",
        "means_r = np.mean(sparsity_level, axis=1)\n",
        "stddev_r = np.std(sparsity_level, axis=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gl8stsSiVRzN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.plot(alphas, means_r, color='red')\n",
        "plt.fill_between(alphas, means_r-stddev_r, means_r+stddev_r, color='red', alpha=0.3)\n",
        "plt.legend(['MC'])\n",
        "plt.title('Sparsity')\n",
        "plt.xlabel('log10(Threshold/GeV)')\n",
        "plt.ylabel('Fraction of cells above threshold')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yKtZTXFzVRzO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from calogan_metrics import get_physical_stats\n",
        "real_phys_stats = get_physical_stats(EnergyDeposit, ParticleMomentum.detach().numpy(), ParticlePoint.detach().numpy())\n",
        "gen_phys_stats = get_physical_stats(EnergyDeposit_gen, ParticleMomentum.detach().numpy(), ParticlePoint.detach().numpy())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AqjV8Q1hVRzO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "precisions, recalls = calc_pr_rec(real_phys_stats, gen_phys_stats, num_clusters=100, num_runs=20)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8FxleHJ7VRzQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pr_aucs = plot_pr_aucs(precisions, recalls)\n",
        "plt.title('Num_clusters={}, num_runs={}, first third'.format(100, 20))\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mqsDUevkVRzR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pr_aucs"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}